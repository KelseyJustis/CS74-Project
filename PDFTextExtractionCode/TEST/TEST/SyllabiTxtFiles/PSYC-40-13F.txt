Computational Neuroscience PBS 40; COSC 16

Fall 2013

Introduction to Computational Neuroscience Prof. Richard Granger
Readings: Readings including class handouts and published articles (list attached), to be posted on blackboard No required textbook for the class.
Course introduction The mind is what the brain does, and the brain is becoming understood computationally. Just as scientific understanding of physics brings with it the ability to manipulate and alter materials and environments and even to create entirely new physical entities, and scientific understanding of biology has enabled the creation of medicines, cures, and even new biological organisms, so a scientific understanding of the brain will confer the ability not only to describe and characterize the mind, but to modify it, enhance it, diagnose and treat its illnesses, and, eventually, to imitate its operation. Computational neuroscience has as its twin goals the scientific and engineering tasks of understanding of how brain computes mind, and using that understanding to characterize and reconstruct these computations. Brain circuits are just circuits, albeit highly unusual ones from an engineering standpoint. Enormous advances over the past decade have provided data on brain architecture and mechanism, advancing hypotheses of how thought arises from neural operation, and enabling initial derivation and formal analysis of candidate constituent algorithms carried out by these circuits. Your brain is composed of low-precision (~ 2 bit), slow (milliseconds per operation), sparsely connected (p(connection) < 0.001) computing elements, yet it far outperforms any extant computer on most complex signal processing tasks that humans and other animals perform readily. Whereas most mammals can recognize complex visual and auditory signals, navigate complex locales and terrains, and perform real-time goal-directed tasks, our ability to construct systems to do so is still surprisingly limited, especially in light of the high level of effort that has been aimed at accomplishing these ends. Indeed, the best current artificial systems that process images or voices, such as face recognition and automated telephone operator systems, are surprisingly limited ­ yet the only reason that we know that these industrial systems can be outperformed is that humans do so. This course will introduce concepts of brain circuits including engineering characteristics of cells, anatomical design and organization of telencephalic (mammalian forebrain) circuitry, physiological operating rules of synapses, cells and networks, synaptic long-term potentiation (LTP); and basics of the mathematical field of "neural networks," including the delta rule for single-layer feedforward networks, the generalized delta rule (backpropagation) for multi-layer networks, dynamic and Hopfield nets, unsupervised learning and competitive learning. The class is intended for students from many different backgrounds. Lectures will include brief but self-contained background on all necessary mathematical tools for the class, including tools from statistics, calculus, and linear algebra. Finally, these neural network analyses will be applied to selected telencephalic structures to illustrate candidate emergent computations from these primary mammalian brain circuits. REQUIREMENTS: This class integrates knowledge of computer science, engineering, psychology, and neuroscience. The prerequisites are Comp Sci 1 or 4 (or old CS 5), or Engineering 20; or Psych 1 or 6. Lectures are required; the majority of material for the class will be contained solely in the lectures. There will also be a series of readings from the literature and via handouts. Note that readings do not substitute for the lectures. GRADING: There will be three exams (20% each), a programming assignment (20%), and a final project (20%).

Computational Neuroscience PBS 40; COSC 16 OUTLINE OF KEY TOPICS

Fall 2013

Part I. Brain: Neuroscience data and mechanism Introduction: Brain. Mind. Intelligence. Artificial intelligence Anatomy of cells, synapses, and circuits Physiology of excitatory and inhibitory neurons and synapses Brain chemistry and pharmacology Composition of telencephalic circuits Synaptic plasticity; long-term potentiation Variants of synaptic plasticity in different circuits
Potentially useful websites containing pointers to background information on neurobiology.
http://www.neuroguide.com http://brainmuseum.org/circuitry/index.html h t t p : / / s i g . b i o s t r. w a s h i n g t o n . e d u / p r o j e c t s / d a / h t t p : / / f a c u l t y. w a s h i n g t o n . e d u / c h u d l e r / f a c t s . h t m l
Part II. Computational approaches: Artificial neural networks Classes of networks and their architectures Math of network operations I [Linear Algebra] Perceptrons, delta rule, backpropagation Math of network operations II [Calculus] Recurrent dynamic networks, Hopfield nets Competitive learning networks Math of network operations III [Statistics] Reinforcement & sequence networks
Potentially useful websites with background/review on ANNs
h t t p : / / w w w. g c . s s r. u p m . e s / i n v e s / n e u r a l / a n n 1 / a n n t u t o r i a l . h t m l http://diwww.epfl.ch/mantra/tutorial/english/ http://www.learnartificialneuralnetworks.com/
Part III. Computational neuroscience: Analysis of brain circuits Paleocortex and unsupervised clustering Striatal complex and reinforcement learning Thalamocortical loops and sequence learning Cortico-striatal and other loops; allometry of brain growth Predictions, extrapolations
Potentially useful websites with background/review on computational neuroscience
http://home.earthlink.net/~perlewitz/

Computational Neuroscience PBS 40; COSC 16

Tentative schedule

PART I: Neuroscience: Data & mechanisms

# Sept

1 17

Introduction

Course outline, goals, requirements

Multidisciplinary fields

2 19

Introduction to neuroanatomy Organization of brain structures Introduction to telencephalon; brain evolution
Reading: Striedter (2006); Anatomy handout

3 24

Introduction to genomics Introduction to biochemistry I
neurotransmitters and receptors Reading: Genomics handout; physiology I

4 26
Oct 51

Introduction to biochemistry II Physiology & pharmacology:
excitatory & inhibitory neurons; synapses & local circuits Reading: Physiology II
Synaptic plasticity Long-term potentiation
Reading: LTP handout Hebb (1949); Intro pp. xi-xix, and Ch. 4. pp 60-78. Martinez & Derreck (1996); Lynch (2003)

63

Review & discussion

78

Exam 1

PART II: Computational tools; Artificial neural networks

8 10

Introduction to artificial neural networks (ANNs)

Simulation and modeling; mathematics of ANNs

Linear algebra I: vectors & matrices

Reading: Linear algebra handout

9 15

Linear algebra II: vector combination; inner product Perceptrons; delta learning rule
Reading: Perceptron handout Reading: Matlab handout

10 17

Extension of perceptrons to multiple layers Extension of delta rule; Backpropagation of error

Fall 2013

Computational Neuroscience PBS 40; COSC 16
Reading: Backpropagation handout; Rumelhart et al. (1986) Introduction to matlab; neural net simulation; simulating backprop

11 22

Introduction to Hopfield networks Analysis of dynamical systems
Reading: Hopfield, 1982 Introduction to unsupervised learning systems Final project proposal discussion

12 24

Clustering, winner-take-all mechanisms Competitive networks
Reading: Zipser & Rumelhart, 1985

13 29

Review and discussion [Final project proposals DUE]

14 31

Exam 2

PART III: Brain and computation

15 Nov 5

Paleocortex; olfactory circuits [Matlab assignment DUE]

Simple telencephalic organization

Reading: Granger 2003

16 7

Clustering; hierarchical clustering Computational costs; scaling; predictions & experiments

12 Striatal complex / basal ganglia Reinforcement learning Reading: Niv 2009

17 14

Thalamocortical loops Unsupervised and supervised classification Reading: Rodriguez et al., 2004; Reading: Chandrashekar et al., 2012 Memory storage and retrieval; data structures; capacity

18 19

Implications

Experimental questions for psychology & neuroscience

Applications: software, hardware, robotics, embedded AI

Review & discussion

Reading: Granger 2011

19

Exam week Exam 3

[Final projects DUE]

Fall 2013

Computational Neuroscience PBS 40; COSC 16

Fall 2013

Readings: Chandrashekar A, Granger R (2012) Derivation of a novel efficient supervised learning algorithm from cortical-
subcortical loops. Front. Comp Neuro, 5(50): 1-17. doi: 10.3389/fncom.2011.00050 Granger R (2003) Neural Computation: Olfactory cortex as a model for telencephalic processing. Learning &
Memory (J.Byrne, Ed.), pp.445-450. Granger R (2006) Engines of the brain. AI Magazine 27: 15-32. Granger R (2011). How brains are built: Principles of computational neuroscience. Cerebrum; The Dana Foundation.
http://dana.org/news/cerebrum/detail.aspx?id=30356 Granger R Wiebe S, Taketani M, Lynch G (1996) Distinct circuits composing the hippocampal region Hippocampus
6:567-578. Hebb D (1949). The organization of behavior. New York: Wiley. Hopfield, J. (1982). Neural networks and physical systems with emergent collective computational abilities. Proc
Natl Acad Sci, 79: 2554-2558. Lynch (2003) Long-term potentiation in the Eocene. Phil. Trans R. Soc. Lond B 358:625-628. Martinez & Derreck (1996) Long-term potentiation and learning Ann. Rev. Psych. 47:173-203. Rodriguez A, Whitson J, Granger R (2004) Derivation and analysis of basic computational operations of
thalamocortical circuits J Cog Neurosci., 16:856-877. Rumelhart D, Zipser D (1985). Feature discovery by competitive learning. Cognitive Sci, 9:75-112. Rumelhart D, Hinton G, Williams R (1986). Learning internal representation by error propagation. Nature 323:
533-536. Striedter G (2006) Precis of Principles of Brain Evolution, Behav & Brain Sci, 29:1-36.

Copyright © 2013, Richard Granger. All rights reserved. Redistribution or commercial use without the expressed, written permission of Richard Granger is prohibited. For information on usage rights, contact Richard Granger at Richard.Granger@dartmouth.edu

